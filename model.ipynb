{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f6e1630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Conv2D, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.activations import linear, relu, sigmoid\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.regularizers import L2\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "from PIL import Image\n",
    "from tensorflow.keras.losses import MSE\n",
    "\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = load_data()\n",
    "\n",
    "print(y_train[0])\n",
    "\n",
    "# Get and scale training data\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# (Y_train, x_train), (Y_test, x_test) = load_data()\n",
    "\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "# x_train = x_train[slice(0,30001)]\n",
    "# Y_train = Y_train[slice(0,30001)]\n",
    "# print(x_train.shape)\n",
    "# x_train = x_train.reshape(-1,1)\n",
    "# x_test = x_test.reshape(-1,1)\n",
    "# print(\"x_train new shape\",x_train.shape)\n",
    "# Y_train = Y_train.reshape((Y_train.shape[0],28**2)).astype('float32')\n",
    "# print(Y_train.shape)\n",
    "# Y_test = Y_test.reshape((Y_test.shape[0],28**2)).astype('float32')\n",
    "\n",
    "# print(tf.reduce_sum(tf.random.normal([1000, 1000])))\n",
    "\n",
    "# Number of units picked with no particular logic behind it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e6bcfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "train_2 = X_train.copy()\n",
    "print(train_2.shape)\n",
    "train_2 = tf.convert_to_tensor(train_2)\n",
    "train_2 = tf.expand_dims(train_2,-1)\n",
    "state_size = train_2.shape[1:]\n",
    "print(state_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0acd3f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n",
      "1conv dimensions 26.0\n",
      "1pool dimensions 8\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 17:13:28.973764: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.4076\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1033\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0770\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0696\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0572\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0552\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0452\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0471\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0408\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0391\n",
      "reached end!\n"
     ]
    }
   ],
   "source": [
    "def convolve_dimensions(side_length,filter_length,padding,stride): # requires even image dimensions\n",
    "    return ((side_length - filter_length + 2*padding)/stride) + 1\n",
    "\n",
    "def pool_dimensions(side_length,pool_length):\n",
    "    return math.floor(side_length/pool_length)\n",
    "\n",
    "# constants\n",
    "print(state_size)\n",
    "dimensions_after_1_conv = convolve_dimensions(state_size[0],3,0,1)\n",
    "print(\"1conv dimensions\",dimensions_after_1_conv)\n",
    "dimensions_after_1_pool = pool_dimensions(dimensions_after_1_conv,3)\n",
    "print(\"1pool dimensions\",dimensions_after_1_pool)\n",
    "\n",
    "# Set up networks\n",
    "conv_network = Sequential([\n",
    "    Conv2D(32,3,input_shape=(state_size)),\n",
    "    MaxPooling2D((3,3)),\n",
    "    Conv2D(64,3),\n",
    "    MaxPooling2D((3,3)),\n",
    "    Flatten(),\n",
    "    Dense(units = 50, activation = \"relu\"),\n",
    "    Dense(units = 25, activation = \"relu\"),\n",
    "    Dense(units = 10, activation = \"softmax\")\n",
    "])\n",
    "\n",
    "conv_network.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "             optimizer=Adam())\n",
    "\n",
    "conv_network.fit(X_train,\n",
    "          y_train, \n",
    "          epochs=10)\n",
    "print(\"reached end!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "420249bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 16:50:21.018722: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 9s 5ms/step - loss: 2.5440\n",
      "Epoch 2/4\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 1.0920\n",
      "Epoch 3/4\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.5845\n",
      "Epoch 4/4\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3850\n",
      "reached end!\n"
     ]
    }
   ],
   "source": [
    "# Build and train model\n",
    "standard_model = Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(units = 100, activation = \"relu\", kernel_regularizer=L2(0.01)),\n",
    "    Dense(units = 25, activation = \"relu\", kernel_regularizer=L2(0.01)), \n",
    "    Dense(units = 10, activation = \"softmax\") # Output\n",
    "])\n",
    "\n",
    "standard_model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "             optimizer=Adam())\n",
    "\n",
    "standard_model.fit(X_train,\n",
    "          y_train, \n",
    "          epochs=10)\n",
    "print(\"reached end!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c05f8db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 25)                2525      \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,285\n",
      "Trainable params: 81,285\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "standard_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60ae5542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 3s 2ms/step\n",
      "[1.1189528e-08 1.9898716e-05 2.1072827e-07 4.2418212e-02 1.5597053e-08\n",
      " 9.5712191e-01 4.7841052e-08 8.4319894e-05 5.2952787e-06 3.5002487e-04]\n",
      "train ratio of correct\n",
      "0.9496\n",
      " 83/313 [======>.......................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 16:52:26.696624: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "test ratio of correct\n",
      "0.9477\n"
     ]
    }
   ],
   "source": [
    "list_of_num = range(10)\n",
    "# list_of_img = np.zeros(list_of_num)\n",
    "# for i in range(len(list_of_img)):\n",
    "#     list_of_img[i] = model.predict(list_of_num[i])\n",
    "predictions_train_2 = standard_model.predict(X_train)\n",
    "#predictions_train = #np.where(probabilities_train >= 0.5, 1, 0)\n",
    "\n",
    "print(predictions_train_2[0])\n",
    "\n",
    "misclassifications_train_2 = 0\n",
    "\n",
    "for i in range(len(predictions_train_2)):\n",
    "    if (np.argmax(predictions_train_2[i]) == y_train[i]):\n",
    "        misclassifications_train_2 += 1\n",
    "        \n",
    "print(\"train ratio of correct\")\n",
    "print(misclassifications_train_2/len(predictions_train_2))\n",
    "\n",
    "##########\n",
    "\n",
    "predictions_test_2 = standard_model.predict(X_test)\n",
    "# predictions_test = np.where(probabilities_test >= 0.5, 1, 0)\n",
    "\n",
    "misclassifications_test_2 = 0\n",
    "\n",
    "for i in range(len(predictions_test_2)):\n",
    "    if (np.argmax(predictions_test_2[i]) == y_test[i]):\n",
    "        misclassifications_test_2 += 1\n",
    "\n",
    "print(\"test ratio of correct\")\n",
    "print(misclassifications_test_2/len(predictions_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bbb441ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 4s 2ms/step\n",
      "[9.3966605e-08 2.0528840e-10 7.5874716e-08 9.6362479e-02 1.6613567e-10\n",
      " 9.0349501e-01 7.8013147e-07 2.6181106e-09 6.6760171e-05 7.4771051e-05]\n",
      "train ratio of correct\n",
      "0.9906666666666667\n",
      "(28, 28, 1)\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "test ratio of correct\n",
      "0.9848\n"
     ]
    }
   ],
   "source": [
    "list_of_num = range(10)\n",
    "# list_of_img = np.zeros(list_of_num)\n",
    "# for i in range(len(list_of_img)):\n",
    "#     list_of_img[i] = model.predict(list_of_num[i])\n",
    "predictions_train = conv_network.predict(train_2)\n",
    "#predictions_train = #np.where(probabilities_train >= 0.5, 1, 0)\n",
    "\n",
    "print(predictions_train[0])\n",
    "\n",
    "misclassifications_train = 0\n",
    "\n",
    "for i in range(len(predictions_train)):\n",
    "    if (np.argmax(predictions_train[i]) == y_train[i]):\n",
    "        misclassifications_train += 1\n",
    "        \n",
    "print(\"train ratio of correct\")\n",
    "print(misclassifications_train/len(predictions_train))\n",
    "\n",
    "##########\n",
    "\n",
    "test_2 = X_test.copy()\n",
    "test_2 = tf.convert_to_tensor(test_2)\n",
    "test_2 = tf.expand_dims(test_2,-1)\n",
    "test_state_size = train_2.shape[1:]\n",
    "print(test_state_size)\n",
    "\n",
    "predictions_test = conv_network.predict(test_2)\n",
    "# predictions_test = np.where(probabilities_test >= 0.5, 1, 0)\n",
    "\n",
    "misclassifications_test = 0\n",
    "\n",
    "for i in range(len(predictions_test)):\n",
    "    if (np.argmax(predictions_test[i]) == y_test[i]):\n",
    "        misclassifications_test += 1\n",
    "\n",
    "print(\"test ratio of correct\")\n",
    "print(misclassifications_test/len(predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bacf67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "20b3d348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  3  2 ...  6  0  3]\n",
      " [ 0  3  2 ... 10  0  3]\n",
      " [ 0  3  2 ... 10  0  5]\n",
      " ...\n",
      " [ 1  4  3 ... 15  0  3]\n",
      " [ 1  1  2 ... 15  0  1]\n",
      " [ 1  4  1 ...  6  1  5]]\n",
      "train ratio of correct\n",
      "0.9864864864864865\n",
      "test ratio of correct\n",
      "0.6262626262626263\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23caefd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
